Sampling Distributions
======================

Combining distributions
-----------------------

To begin, we will see that when two distributions are combined, their sums and variances are added together.

Imagine I had two normals: one with mean=5, sd=3; and one with mean=10, sd = 4.
Then the combined mean would be 15 (5 + 10).
And the combined standard deviation would be 5 (sqrt(3^2 + 4^2)).

Let's see that in action:
```{r}
comb.norm = rnorm(10000,mean=5,sd=3) + rnorm(10000,mean=10,sd=4)
mean(comb.norm)
sd(comb.norm)
```

The best part is - we know exactly what this distribution is going to look like.
Any time you add two normal distributions together, the resulting distribution will be normal
```{r}
hist(comb.norm)
```

Another test for normality is the 'qq plot'.
This plots the quantiles of two distributions against each other.
If it's a straight line, then you know that the two distributions are the same.
So an easy way to do a quick check for normality is to qq plot a distribution against the normal.
This is easy with R - qqnorm() will do the normal comparison automatically for you.

And if you want to add a straight line, you can with qqline():
```{r}
qqnorm(comb.norm)
qqline(comb.norm)
```

Okay - so if you add two normals, you can figure out the combined mean and sd easily...
But does this hold for other distributions?
What if we combine two exponential distributions?

Let's first see what a single distribution looks like.
Note that in the exponential distribution, mean and sd = 1/rate (4, in this case)
```{r}
sing.exp = rexp(10000,rate=.25) #what do you think the rexp command is doing?
mean(sing.exp)
sd(sing.exp)
```

The exponential distribution is decidedly non-normal:
```{r}
plot(seq(0,10,by=.01),dexp(seq(0,10,by=.01),rate=.25),type = 'l')
```

Now let's add two exponentials with mean/sd = 4.
What will the combined means and standard dev be?
```{r}
comb.2exp = rexp(10000,rate = .25) + rexp(10000,rate = .25)
```

The mean should be 8 (4 + 4)
```{r}
mean(comb.2exp)
```

And the sd should be about 5.66 (sqrt(4^2 + 4^2) = 4*sqrt(2))
```{r}
sd(comb.2exp)
```

But how does it look?
Here we're going to do a density plot - this is basically just a smoothed histogram
```{r}
plot(density(comb.2exp),xlim = c(0,20))
```

Well that's not a normal...
But it's not an exponential distribution either...
What if we add three exponentials?
```{r}
comb.3exp = rexp(10000,rate = .25) + rexp(10000,rate = .25) + rexp(10000,rate = .25)
```

Again, the mean should be 12, and the sd should be ~6.92 (4*sqrt(3))
```{r}
mean(comb.3exp)
sd(comb.3exp)
```

And what does this look like?
```{r}
plot(density(comb.3exp),xlim = c(0,30))
```

That's starting to look like a skewed normal...

So let's now sum 10 of these distributions:
```{r}
comb.10exp = replicate(10000,sum(rexp(10,rate = .25)))
```

The mean should be 40, and the sd should be ~12.65 (4*sqrt(10))
```{r}
mean(comb.10exp)
sd(comb.10exp)
```

And visualize:
```{r}
plot(density(comb.10exp),xlim = c(0,100))
```

Well this is starting to look more normal...
But if we qq plot it, we can see some skew:
```{r}
qqnorm(comb.10exp)
qqline(comb.10exp)
```

And 100?
```{r}
comb.100exp = replicate(10000,sum(rexp(100,rate = .25)))
```

The mean should be 400, and the sd should be 40 (4*sqrt(100))
```{r}
mean(comb.100exp)
sd(comb.100exp)
```

And visualize:
```{r}
plot(density(comb.100exp),xlim = c(0,1000))
```

This looks pretty normal.
And the qq plot will confirm that for us (it's a little off in the tails, but barely):
```{r}
qqnorm(comb.100exp)
qqline(comb.100exp)
```

> But this is the key thing: if you keep adding up distributions,
> the resulting distribution will be normal (at a certain point), regardless of the underlying distributions!

And here's the greatest part about it... what if you didn't know the mean of the exponential distribution?
Well, if you took 100 samples, what would your best esimate of the mean of the distribution be?

How about the mean of the 100 samples?
Which of course, is just the sum of all of the samples, divided by 100...

So if we know that the sum of n samples from a distribution is distributed as a normal with a mean of pop.mean times n and a standard deviation of pop.sd times sqrt(n)... then if you divide both of those by n, your estimate of the mean will be normal with a mean of pop.mean and a standard deviation of pop.sd/sqrt(n)
```{r}
mean.exp = comb.100exp/100
mean(mean.exp) # Should be ~4
sd(mean.exp) # Should be ~ 0.4 (4 / sqrt(100))
hist(mean.exp) # Looks pretty normal...
```

Central Limit Theorem
---------------------

Here we're going to demonstrate the Central Limit Theorem in action

Let's say we have a population with some attribute that has a mean of 1 and sd of 3.
Often in our experiments, we'll only be able to take a small sample from the population - say 20 people.
Then our best estimate of the population mean will be the mean of that sample

Let's try it:
```{r}
mean(rnorm(20,mean = 1, sd = 3))
```

But we don't get the exact population mean...
Let's try it again:
```{r}
mean(rnorm(20,mean = 1, sd = 3))
```

That's not quite it either...

So let's do this a large number of times
```{r}
lots.o.samples = replicate(10000,mean(rnorm(20,mean=1,sd=3)))
```

The mean should be pretty close to 1 (or we would have a biased statistic)...
```{r}
mean(lots.o.samples)
```

That's good... if we do this a lot of times, on average the mean of the sample will be the population mean

And we can look at the distribution
```{r}
hist(lots.o.samples, breaks = seq(-4,6,by=.1))
```

That looks pretty normally distributed..
So what's the standard deviation of the sampled means?
```{r}
sd(lots.o.samples)
```

Well, recall in the last section, we showed that summing lots of distributions made a normal distribution.
And that if you summed the same distribution over and over and divided by n, that's the same as taking a mean of a sample.
And this mean will be normally distributed around the population mean with a standard deviation of pop.sd / sqrt(n)--or the standard error.

And that's what we did with lots.o.samples.
We took a 20-person sample, and found the mean over and over again.
So the standard deviation of the mean should be pop.sd / sqrt(n).
And we know that the population standard deviation is 3 (we defined it as such).
So the standard deviation of the means should be:
```{r}
3/sqrt(20)
```

So if we take lots and lots of these 20-person samples,
the mean of those samples is distributed as we would expect.

But what if we were able to take larger samples?
What would happen to our estimate of the mean?

According to what we've learned, the average mean would still be 1.
But as we increase n, the deviation of these means will decrease.

Let's try this with 100 people per sample
```{r}
lots.o.samples = replicate(10000,mean(rnorm(100,mean=1,sd=3)))
hist(lots.o.samples, breaks = seq(-4,6,by=.1))
mean(lots.o.samples) # ~1
sd(lots.o.samples) # ~ 3/sqrt(100) = 0.3
```

And for a side by side comparison:
```{r}
hist(lots.o.samples,breaks = seq(-6,8,by=.1),xlim = c(-4,6),ylim=c(0,1500),main = 'n = 5')
lots.o.samples = replicate(10000,mean(rnorm(20,mean=1,sd=3)))
hist(lots.o.samples,breaks = seq(-6,8,by=.1),xlim = c(-4,6),ylim=c(0,1500),main = 'n = 20')
lots.o.samples = replicate(10000,mean(rnorm(100,mean=1,sd=3)))
hist(lots.o.samples,breaks = seq(-6,8,by=.1),xlim = c(-4,6),ylim=c(0,1500),main = 'n = 100')
par(mfrow = c(1,1))
```

So far we're assuming that the population attribute is distributed normally. 
But this is often not the case.
The great part about the central limit theorem is it *doesn't matter* what the underlying distribution is as long as the sample is large enough.

Let's try this by generating uniform random numbers between 0 and 1.
We can get a sample of 20 of these.
```{r}
mean(runif(20))
```

The mean should be 0.5 - and we're getting close to it...
But we have R; so let's test it by simulation!
```{r}
lots.o.samples = replicate(10000,mean(runif(20)))
```

How is this shaped?
```{r}
hist(lots.o.samples,breaks = seq(0,1,by=.01))
```

Looks pretty normal, right?
So what are the mean and standard devation of this distribution?
```{r}
mean(lots.o.samples)
sd(lots.o.samples)
```

Does this match with intuition?
Well, the mean should be 0.5.
And take it from me on faith that the sd of a uniform from 0 to 1 is ~0.288.
So the sd should be:
```{r}
0.288/sqrt(20)
```

If we increase the number of people in each sample, this again gets more refined:
```{r}
lots.o.samples = replicate(10000,mean(runif(100)))
hist(lots.o.samples,breaks = seq(0,1,by=.01))
sd(lots.o.samples) # .288/sqrt(100) = .0288
```

Note that even with a uniform distribution and 5 people per sample,
the distribution of the sample means is still pretty normal
(it will have fat tails, but it isn't too bad)
```{r}
qqnorm(lots.o.samples)
qqline(lots.o.samples)
```

But what if the data itself is EXTREMELY non-normal.
We're going to define a probability distribution function for a very odd function on the range 0 to 1.
Don't worry for now exactly how this works - we'll explain conditionals later.

```{r}
dodd = function(x) {
  if(length(x) > 1) {return(sapply(x,dodd))}
  if(x < 0) {return(0)}
  else if (x < .1) {return(2)}
  else if (x < .4) {return(0)}
  else if (x < .6) {return(10*(x-.4))}
  else if (x < .7) {return(0)}
  else if (x < .8) {return(4)}
  else if (x < .9) {return(0)}
  else if (x < 1) {return(40*(1-x))}
  else {return(0)}
}
```

But what does this distribution look like?
```{r}
plot(seq(-.1,1.1,by=.001),dodd(seq(-.1,1.1,by=.001)),type='l',ylab='f(x)',xlab='x')
```

Then we can define a random draw.
Since this function is defined only on 0 < x < 1, we can draw randomly from it using runif. 
Just call the function on runif to get one sample here
```{r}
rodd = function(n) {
  return(dodd(runif(n)))
}
```

So we can get one sample
```{r}
rodd(1)
```

With that in mind, what does the sampling distribution look like?
Let's take lots of samples of 20 people
```{r}
lots.o.samples = replicate(10000,mean(rodd(20)))
hist(lots.o.samples, breaks = seq(0,4,by=.1),xlim = c(0,2.5))
```

And we can increase the sample size to refine our observations
```{r}
lots.o.samples = replicate(10000,mean(rodd(100)))
hist(lots.o.samples, breaks = seq(0,4,by=.1),xlim = c(0,2.5))
mean(lots.o.samples) # ~ 1
sd(lots.o.samples) # ~ 1.34/sqrt(100) = .134
```

But now let's take a small sample:
```{r}
lots.o.samples = replicate(10000,mean(rodd(5)))
hist(lots.o.samples, breaks = seq(0,4,by=.1),xlim = c(0,2.5))
```

Uh oh... this doesn't look normal at all...
But many of our statistical tests for the mean require that it come from a normal distribution.
So we can't build confidence intervals or do standard statistical tests on the mean...

We would need a larger sample to ensure that the sampling mean is normally distributed.
Usually about 25-30 samples guarantees normality.

**That's a good RULE OF THUMB - 30+ samples won't steer you wrong!**

Let's see how that works with these data.
Here we'll plot the sampling distribution for samples sizes 5, 10, 15, 20, 25 & 30.
Don't worry about the for loop yet (just saves typing time).
```{r}
par(mfrow = c(2,3))
for(n in seq(5,30,by=5)) {
  samps = replicate(10000,mean(rodd(n)))
  title = paste('n=',n)
  hist(samps, breaks = seq(0,4,by=.1),xlim = c(0,2.5), main=title)
}
par(mfrow = c(1,1))
```

And let's see how that looks in qq plot form:
```{r}
par(mfrow = c(2,3))
for(n in seq(5,30,by=5)) {
  samps = replicate(10000,mean(rodd(n)))
  title = paste('n=',n)
  qqnorm(samps, main=title)
  qqline(samps)
}
par(mfrow = c(1,1))
```

Notice how the distribution gets less skewed as the sample size increases--around 30 is the magic number!
